---
description: "Auto-debugging system vá»›i fongdebug module - tá»± Ä‘á»™ng log, run, analyze vÃ  fix Python code"
version: "2025-09-04T20:00:00Z"
context: "Python development auto-debug workflow"
session_id: "2025-09-04--09-01-pm"
conversation_id: "c2b3f9bd-d58a-41a9-8155-e4826841582e"
---

# ğŸ› INSTRUCTIONS: AUTO-DEBUG PYTHON - FONGDEBUG MODULE

## ğŸ¯ Má»¤C ÄÃCH

Tá»± Ä‘á»™ng hÃ³a quy trÃ¬nh debug Python code báº±ng cÃ¡ch:
1. **LuÃ´n log má»i thá»©** vÃ o `./src/logs/debug.log`
2. **Cháº¡y code vÃ  Ä‘á»c output** (console + log files)  
3. **AI tá»± think vÃ  fix** cho tá»›i khi code works
4. **Production mode**: Chá»‰ remove fongdebug khi deploy

## ğŸ—ï¸ FONGDEBUG MODULE ARCHITECTURE

### **Core Structure**
```python
# Trong má»—i Python file:
from fongdebug import debug_logger, auto_monitor

# Auto-logging decorator
@auto_monitor("function_name")
def any_function():
    debug_logger.info("Function started")
    # ... business logic
    debug_logger.debug("Intermediate state: {data}")
    return result

# Log directory: ./src/logs/debug.log (LUÃ”N CÃ“ RELATIVE Tá»šI SRC)
```

### **File Structure Pattern**
```
project/
â”œâ”€â”€ src/                     # Source code directory
â”‚   â”œâ”€â”€ logs/               # LOG DIR - LUÃ”N TRONG SRC
â”‚   â”‚   â””â”€â”€ debug.log       # Main debug log
â”‚   â”œâ”€â”€ fongdebug.py        # Debug module
â”‚   â”œâ”€â”€ module1.py          # Business code + fongdebug
â”‚   â””â”€â”€ module2.py          # Business code + fongdebug
â””â”€â”€ main.py                 # Entry point + fongdebug
```

## ğŸ”§ FONGDEBUG MODULE SPECIFICATION

### **1. Auto-Logger (fongdebug.py)**
```python
import logging
import functools
import traceback
import sys
from pathlib import Path
from datetime import datetime

class FongDebugger:
    def __init__(self):
        self.setup_logging()
    
    def setup_logging(self):
        """Setup debug log in ./src/logs/ directory"""
        # Determine src/logs path
        current_file = Path(__file__)
        if current_file.parent.name == 'src':
            log_dir = current_file.parent / 'logs'
        else:
            # If fongdebug not in src, find src directory
            src_dir = current_file.parent / 'src'
            if not src_dir.exists():
                # Create src and logs if not exist
                src_dir.mkdir(exist_ok=True)
            log_dir = src_dir / 'logs'
        
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / 'debug.log'
        
        # Configure comprehensive logging
        logging.basicConfig(
            level=logging.DEBUG,
            format='%(asctime)s - %(name)s:%(lineno)d - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, mode='a'),
                logging.StreamHandler(sys.stdout)
            ],
            force=True
        )
        
        self.logger = logging.getLogger('fongdebug')
        self.logger.info(f"ğŸ› FongDebug initialized - {datetime.now()}")
    
    def auto_monitor(self, func_name=""):
        """Decorator Ä‘á»ƒ auto-log function execution"""
        def decorator(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                name = func_name or func.__name__
                self.logger.info(f"â–¶ï¸ START: {name}")
                self.logger.debug(f"Args: {args}, Kwargs: {kwargs}")
                
                try:
                    result = func(*args, **kwargs)
                    self.logger.info(f"âœ… SUCCESS: {name}")
                    self.logger.debug(f"Result: {type(result)} - {str(result)[:200]}")
                    return result
                except Exception as e:
                    self.logger.error(f"âŒ ERROR in {name}: {str(e)}")
                    self.logger.error(f"Traceback:\n{traceback.format_exc()}")
                    raise
            return wrapper
        return decorator
    
    def log_state(self, message, data=None):
        """Log intermediate states"""
        self.logger.debug(f"ğŸ” STATE: {message}")
        if data is not None:
            self.logger.debug(f"Data: {str(data)[:500]}")

# Global instance
_debugger = FongDebugger()
debug_logger = _debugger.logger
auto_monitor = _debugger.auto_monitor
log_state = _debugger.log_state
```

### **2. Integration Pattern**
```python
# Trong má»—i module .py:
from fongdebug import debug_logger, auto_monitor, log_state

@auto_monitor("load_data")
def load_data(file_path):
    debug_logger.info(f"Loading data from: {file_path}")
    
    try:
        data = pd.read_csv(file_path)
        log_state("Data loaded", f"Shape: {data.shape}")
        return data
    except Exception as e:
        debug_logger.error(f"Failed to load data: {e}")
        raise

@auto_monitor("process_pipeline") 
def main_pipeline():
    debug_logger.info("ğŸš€ Starting main pipeline")
    
    # Step 1
    log_state("Step 1: Data loading")
    data = load_data("input.csv")
    
    # Step 2  
    log_state("Step 2: Processing", f"Records: {len(data)}")
    processed = process_data(data)
    
    debug_logger.info("âœ… Pipeline completed successfully")
    return processed
```

## ğŸ¤– AI AUTO-DEBUG WORKFLOW

### **BÆ¯á»šC 1: EXECUTE & MONITOR**
```bash
# AI cháº¡y Python script
python main.py

# AI simultaneously monitors:
# - Console output (STDOUT/STDERR)  
# - Log file: tail -f src/logs/debug.log
```

### **BÆ¯á»šC 2: ERROR DETECTION & ANALYSIS**
```python
# AI detects errors from:
# 1. Exit code != 0
# 2. Exception trong console
# 3. ERROR/CRITICAL entries trong debug.log
# 4. Stack traces

# AI analysis workflow:
def ai_analyze_error():
    """AI tá»± Ä‘á»™ng phÃ¢n tÃ­ch lá»—i"""
    
    # Read console output
    console_output = capture_stdout_stderr()
    
    # Read debug.log
    with open('src/logs/debug.log', 'r') as f:
        log_content = f.read()
    
    # Extract error patterns
    errors = extract_errors(console_output, log_content)
    
    # AI thinking process:
    for error in errors:
        print(f"ğŸ” ANALYZING ERROR: {error}")
        root_cause = ai_determine_root_cause(error)
        fix_strategy = ai_generate_fix_strategy(root_cause)
        ai_apply_fix(fix_strategy)
    
    # Re-run and verify
    return ai_verify_fix()
```

### **BÆ¯á»šC 3: AUTO-FIX LOOP**
```python
def autodebug_loop(max_iterations=5):
    """AI auto-debug until success"""
    
    for iteration in range(max_iterations):
        debug_logger.info(f"ğŸ”„ Auto-debug iteration {iteration + 1}")
        
        # Execute code
        exit_code, stdout, stderr = run_python_script()
        
        # Check success
        if exit_code == 0 and no_errors_in_logs():
            debug_logger.info("âœ… AUTO-DEBUG SUCCESS - Code works!")
            return True
        
        # Analyze errors
        errors = ai_analyze_errors(stdout, stderr, 'src/logs/debug.log')
        
        # Generate fixes  
        fixes = ai_generate_fixes(errors)
        
        # Apply fixes
        ai_apply_fixes(fixes)
        
        debug_logger.info(f"ğŸ› ï¸ Applied {len(fixes)} fixes")
    
    debug_logger.error("âŒ AUTO-DEBUG FAILED after max iterations")
    return False
```

## ğŸ“‹ AI EXECUTION INSTRUCTIONS

### **ğŸ¯ WHEN TO USE AUTO-DEBUG**
```bash
# MANDATORY usage khi:
# 1. Developing new Python modules
# 2. Debugging existing code issues  
# 3. Integration testing
# 4. Performance troubleshooting
# 5. Code refactoring validation
```

### **ğŸ”¥ AI AUTO-DEBUG PROTOCOL**

#### **Phase 1: Setup**
```bash
# 1. Ensure fongdebug module exists
# 2. Verify log directory: src/logs/
# 3. Check all .py files have fongdebug imports
```

#### **Phase 2: Execute & Monitor**
```bash
# Run vá»›i comprehensive monitoring:
python main.py 2>&1 | tee execution.log &
tail -f src/logs/debug.log &

# AI reads BOTH streams simultaneously
```

#### **Phase 3: Error Analysis**
```python
# AI systematic error analysis:
def ai_comprehensive_analysis():
    # 1. Parse exception stack traces
    # 2. Identify missing imports/dependencies  
    # 3. Check data type mismatches
    # 4. Validate file paths and permissions
    # 5. Analyze logic flow issues
    # 6. Check configuration problems
```

#### **Phase 4: Fix Generation**
```python
# AI generates targeted fixes:
def ai_generate_targeted_fixes(errors):
    fixes = []
    for error in errors:
        if "ModuleNotFoundError" in error:
            fixes.append(generate_import_fix(error))
        elif "FileNotFoundError" in error:
            fixes.append(generate_path_fix(error))
        elif "TypeError" in error:
            fixes.append(generate_type_fix(error))
        # ... more error patterns
    return fixes
```

#### **Phase 5: Fix Application** 
```python
# AI applies fixes systematically:
def ai_apply_fixes_systematically(fixes):
    for fix in fixes:
        debug_logger.info(f"ğŸ› ï¸ Applying fix: {fix.description}")
        
        # Apply code changes
        apply_code_change(fix)
        
        # Test fix immediately
        if test_fix_works(fix):
            debug_logger.info(f"âœ… Fix successful: {fix.description}")
        else:
            debug_logger.error(f"âŒ Fix failed: {fix.description}")
            rollback_change(fix)
```

## ğŸš€ USAGE EXAMPLES

### **Example 1: Data Processing Pipeline**
```python
# main.py
from fongdebug import debug_logger, auto_monitor

@auto_monitor("data_pipeline")
def main():
    debug_logger.info("ğŸš€ Starting data pipeline")
    
    # AI auto-logs má»i step
    data = load_csv_data()
    cleaned = clean_data(data)  
    results = analyze_data(cleaned)
    
    debug_logger.info("âœ… Pipeline completed")
    return results

# AI execution:
# 1. python main.py
# 2. Monitor src/logs/debug.log  
# 3. If errors â†’ analyze â†’ fix â†’ retry
# 4. Loop until success
```

### **Example 2: Machine Learning Training**
```python
from fongdebug import debug_logger, auto_monitor, log_state

@auto_monitor("ml_training")
def train_model():
    debug_logger.info("ğŸ¤– Starting ML training")
    
    # Load data
    log_state("Loading training data")
    X, y = load_training_data()
    
    # Train model
    log_state("Training model", f"Data shape: {X.shape}")
    model = RandomForestClassifier()
    model.fit(X, y)
    
    # Evaluate
    score = model.score(X_test, y_test)
    log_state("Model evaluation", f"Accuracy: {score}")
    
    debug_logger.info(f"âœ… Training completed - Accuracy: {score}")
    return model

# AI autodebug sáº½:
# - Detect import errors â†’ fix imports
# - Detect data issues â†’ fix data loading
# - Detect model errors â†’ fix parameters  
# - Loop until training succeeds
```

## ğŸ›ï¸ PRODUCTION VS DEVELOPMENT

### **Development Mode (DEFAULT)**
```python
# LUÃ”N CÃ“ fongdebug trong development
from fongdebug import debug_logger, auto_monitor
```

### **Production Mode** 
```python  
# CHá»ˆ KHI DEPLOY production má»›i remove:
# Option 1: Comment out fongdebug
# from fongdebug import debug_logger, auto_monitor

# Option 2: Use environment variable
import os
if os.getenv('PRODUCTION') != 'true':
    from fongdebug import debug_logger, auto_monitor
else:
    # Production logging
    import logging
    debug_logger = logging.getLogger(__name__)
```

## âš ï¸ CRITICAL SUCCESS FACTORS

### **1. MANDATORY LOGGING**
- Má»ŒI function trong development PHáº¢I cÃ³ `@auto_monitor`
- Má»ŒI intermediate state PHáº¢I log vá»›i `log_state()` 
- Má»ŒI error PHáº¢I captured vá»›i full traceback

### **2. AI AUTO-FIX REQUIREMENTS**
- AI PHáº¢I Ä‘á»c Cáº¢ console output VÃ€ debug.log  
- AI PHáº¢I analyze errors systematically (stack trace, types, logic)
- AI PHáº¢I apply fixes incrementally vÃ  test each fix
- AI PHáº¢I loop until success (max 5 iterations)

### **3. LOG FILE MANAGEMENT**
```python
# Log rotation Ä‘á»ƒ avoid huge files:
def rotate_debug_log():
    log_file = Path('src/logs/debug.log')
    if log_file.stat().st_size > 10 * 1024 * 1024:  # 10MB
        backup = f"debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        log_file.rename(Path('src/logs') / backup)
```

## ğŸ“Š SUCCESS METRICS

### **âœ… AUTO-DEBUG THÃ€NH CÃ”NG KHI:**
- Code cháº¡y hoÃ n chá»‰nh khÃ´ng lá»—i (exit code = 0)
- KhÃ´ng cÃ³ ERROR/CRITICAL trong debug.log
- Console output clean (no exceptions)
- Business logic outputs Ä‘Ãºng expected results
- Performance acceptable (khÃ´ng infinite loops)

### **ğŸ“ˆ KPI TRACKING**
```python
# Track auto-debug effectiveness:
# - Success rate (% fixes thÃ nh cÃ´ng)
# - Average iterations per fix
# - Common error patterns  
# - Fix accuracy rate
```

## ğŸ”— INTEGRATION Vá»šI FONG TOOLS

### **Memory Integration**
```bash
# Auto-save debug session vÃ o memory:
echo "## Auto-Debug Session $(date)" >> .fong/.memory/debug_sessions.md
echo "- Errors found: [list]" >> .fong/.memory/debug_sessions.md  
echo "- Fixes applied: [list]" >> .fong/.memory/debug_sessions.md
echo "- Success: [yes/no]" >> .fong/.memory/debug_sessions.md
```

### **Tool Integration**
```bash
# Use modern tools cho analysis:
smart-search-fz-rg-bm25 "ERROR" src/logs/ --show-content   # Primary log search
rg "ERROR|CRITICAL" src/logs/debug.log                      # Fallback regex search
fd "*.py" src/ --exec grep -l "fongdebug" # Check fongdebug usage
bat src/logs/debug.log                    # Pretty view logs
```

## ğŸ¯ TRIáº¾T LÃ

> **"Debug early, debug often, debug automatically"**
> 
> Thay vÃ¬ manually debug má»—i láº§n cÃ³ lá»—i, AI sáº½ tá»± Ä‘á»™ng:
> - Log comprehensive data
> - Detect vÃ  analyze errors  
> - Generate vÃ  apply fixes
> - Verify fixes work
> - Loop until success
> 
> Má»¥c tiÃªu: **Zero manual debugging** trong development workflow.

---

**ğŸ“ LÆ¯U Ã QUAN TRá»ŒNG:**
1. **fongdebug LUÃ”N ACTIVE** trong development
2. **./src/logs/debug.log** lÃ  single source of truth
3. **AI pháº£i loop fix** cho Ä‘áº¿n khi code works hoÃ n toÃ n  
4. **Only remove fongdebug** khi chuyá»ƒn production
5. **Log files** pháº£i comprehensive vÃ  readable cho AI analysis
